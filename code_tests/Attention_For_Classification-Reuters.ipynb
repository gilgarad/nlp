{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gilgarad/nlp_nlu/blob/master/jupyter_colab/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS0WHOcAfOz1"
   },
   "source": [
    "# Mixed code and reimplementations with additional implementation from \n",
    "# 1. Code Structure: https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "# 2. Attention: https://github.com/philipperemy/keras-attention-mechanism\n",
    "# 3. Dataset(Movie Review): https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "cWB-ypQAd3p4",
    "outputId": "a5ac7593-5e4a-456a-d71e-623de17644cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Flatten, BatchNormalization, Activation, \\\n",
    "Dropout, Input, multiply, Permute, Reshape, merge, Concatenate, Lambda, \\\n",
    "RepeatVector, concatenate, TimeDistributed, Multiply\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7LvTcrGd6a0"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 20152018\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMh6gWv6d6eU"
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import imdb\n",
    "from keras.datasets import reuters, imdb\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sE-xXtFIJsyj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PEf0tMHed508",
    "outputId": "59504960-6dd6-409e-fcc7-75423c5c1f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download. Currently only for 1. imdb and 2. reuter\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "print('Data download. Currently only for 1. imdb and 2. reuter')\n",
    "# dataset_name = 'imdb'\n",
    "dataset_name = 'reuters'\n",
    "\n",
    "dataset_dict = {'imdb': imdb, 'reuters': reuters}\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = dataset_dict[dataset_name].load_data(path=dataset_name + \".npz\",\n",
    "                                                                            num_words=None,\n",
    "                                                                            skip_top=0,\n",
    "                                                                            maxlen=None,\n",
    "                                                                            seed=seed,\n",
    "                                                                            start_char=1,\n",
    "                                                                            oov_char=2,\n",
    "                                                                            index_from=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvk4D5-td58U",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:\n",
      "Shape: (8982,)\n",
      "x_test:\n",
      "Shape: (2246,)\n",
      "Example: [list([1, 195, 13780, 15752, 5, 141, 4287, 130, 71, 9262, 68, 5, 78, 3145, 561, 900, 6, 2156, 603, 141, 1211, 76, 8, 16, 33, 116, 10, 310, 7, 4, 49, 6, 83, 127, 561, 51, 36, 487, 6, 3391, 432, 67, 4, 561, 41, 263, 9, 118, 371, 77, 41, 45, 2912, 7, 25, 362, 9262, 9, 141, 5172, 1197, 1416, 71, 3666, 7, 50, 286, 1068, 9, 2094, 450, 9, 697, 7019, 103, 595, 119, 20, 4093, 55, 306, 6, 1934, 172, 10, 73, 4252, 6, 2570, 112, 6766, 6842, 6803, 111, 149, 17, 12])]\n",
      "\n",
      "y_train:\n",
      "Shape: (8982,)\n",
      "y_test:\n",
      "Shape: (2246,)\n",
      "Example [4]\n"
     ]
    }
   ],
   "source": [
    "# # Label Normalize! encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(y_train)\n",
    "# encoded_Y = encoder.transform(y_train)\n",
    "# y_train = np_utils.to_categorical(encoded_Y)\n",
    "# encoded_Y = encoder.transform(y_test)\n",
    "# y_test = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "\n",
    "# Check input and output shape\n",
    "\n",
    "print('x_train:')\n",
    "print('Shape:', x_train.shape)\n",
    "print('x_test:')\n",
    "print('Shape:', x_test.shape)\n",
    "print('Example:', x_train[:1])\n",
    "print('')\n",
    "print('y_train:')\n",
    "print('Shape:', y_train.shape)\n",
    "print('y_test:')\n",
    "print('Shape:', y_test.shape)\n",
    "print('Example', y_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "99_hZh4ikgUD",
    "outputId": "e964dc9e-cea3-4b06-ccfc-72582769442c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index \"man\": 2792\n",
      "Word Index \"save\": 2854\n",
      "Number of words: 30979\n"
     ]
    }
   ],
   "source": [
    "# Check Dictionary\n",
    "word_index = dataset_dict[dataset_name].get_word_index(path=dataset_name + \"_word_index.json\")\n",
    "num_words = len(word_index.keys())\n",
    "print('Word Index \"man\":', word_index['man'])\n",
    "print('Word Index \"save\":', word_index['save'])\n",
    "print('Number of words:', num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check up the length of each input data. I will choose the mid length of three measured out of lengths as seq_max_length\n",
      "Max Length: 2376\n",
      "Median Length: 95.0\n",
      "Average Length: 145.96419665122906\n",
      "\n",
      "seq_max_length: 146\n"
     ]
    }
   ],
   "source": [
    "# Check max length\n",
    "print('Check up the length of each input data. I will choose the mid length of three measured out of lengths as seq_max_length')\n",
    "x_train_legnth = [len(x) for x in x_train]\n",
    "x_test_length = [len(x) for x in x_test]\n",
    "max_length = np.max(np.concatenate([x_train_legnth, x_test_length]))\n",
    "median_length = np.median(np.concatenate([x_train_legnth, x_test_length]))\n",
    "average_length = np.mean(np.concatenate([x_train_legnth, x_test_length]))\n",
    "print('Max Length:', max_length)\n",
    "print('Median Length:', median_length)\n",
    "print('Average Length:', average_length)\n",
    "print('')\n",
    "\n",
    "seq_max_length = np.median([max_length, median_length, average_length])\n",
    "seq_max_length = int(seq_max_length // 1 + 1)\n",
    "print('seq_max_length:', seq_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vA7CCgRyu4U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences with seq_max_length, and padding type will be \"post\"\n",
      "Number of categories: 46\n"
     ]
    }
   ],
   "source": [
    "# Pad input sequences\n",
    "print('Pad sequences with seq_max_length, and padding type will be \"post\"')\n",
    "_x_train = pad_sequences(x_train, maxlen=seq_max_length, padding='post')\n",
    "_x_test = pad_sequences(x_test, maxlen=seq_max_length, padding='post')\n",
    "_y_train = np_utils.to_categorical(y_train)\n",
    "_y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_categories = _y_train.shape[1]\n",
    "print('Number of categories:', num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "lstm_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztuHR2UDd5-8"
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(num_words, embedding_dim))\n",
    "        model.add(Bidirectional(LSTM(lstm_dim, return_sequences=False)))\n",
    "        model.add(Dense(num_categories, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1360
    },
    "colab_type": "code",
    "id": "8Z5kH3DUd6BW",
    "outputId": "b257573e-c483-404a-fd3f-877d6c67558f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "# estimator = KerasClassifier(build_fn=create_baseline, epochs=30, batch_size=512, verbose=1)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(estimator, _x_train, _y_train, cv=kfold)\n",
    "# print(estimator.summary())\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_baseline()\n",
    "print(model.summary())\n",
    "model.fit(x=_x_train, y=_y_train, validation_data=(_x_test, _y_test), batch_size=256, verbose=1, epochs=100)\n",
    "loss, metrics = model.evaluate(_x_test, _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Concept - Encoder / Decoder Style (Luong Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_dim = 128\n",
    "embedding_dim = 200\n",
    "lstm_dim = 128\n",
    "\n",
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "def attention_baseline(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        inputs = Input(input_shape)\n",
    "        embeded_enc = Embedding(num_words, embedding_dim)(inputs)\n",
    "#         encoder = Bidirectional(LSTM(lstm_dim, return_sequences=True, return_state=True))\n",
    "        encoder = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder(embeded_enc)\n",
    "        encoder_output_states = [encoder_state_h, encoder_state_c]\n",
    "        \n",
    "        decoder_inputs = Input((1, ))\n",
    "        embeded_dec = Embedding(1, embedding_dim)(decoder_inputs)\n",
    "        decoder = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec, initial_state=encoder_output_states)\n",
    "#         decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec)\n",
    "        \n",
    "        # Make Attention Layer\n",
    "        reapeat_d = repeat_vector(seq_length=seq_max_length, axis=2)(decoder_outputs)\n",
    "        repeat_e = repeat_vector(seq_length=1, axis=1)(encoder_outputs)\n",
    "\n",
    "        attention_concat_outputs = Concatenate()([reapeat_d, repeat_e])\n",
    "        dense1_score = Dense(attention_score_dim, activation='tanh')(attention_concat_outputs)\n",
    "        score_layer = Dense(1)(dense1_score)\n",
    "        dense2_score = Reshape((1, seq_max_length))(score_layer) # reshape to be 2 dims\n",
    "        softmax_score = Activation('softmax')(dense2_score)\n",
    "        \n",
    "        repeat_score_layer = repeat_vector(attention_score_dim, 2)\n",
    "        repeat_score = repeat_score_layer(softmax_score)\n",
    "\n",
    "        permute_e = Permute((2, 1))(encoder_outputs)\n",
    "        repeat_e_layer = repeat_vector(1, 1)\n",
    "        repeat_e = repeat_e_layer(permute_e)\n",
    "\n",
    "        attended_mat_layer = Multiply()\n",
    "        attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
    "\n",
    "        context_layer = Lambda(lambda x: K.sum(x, axis=-1),\n",
    "                                     lambda x: tuple(x[:-1]))\n",
    "        context = context_layer(attended_mat)\n",
    "\n",
    "        concat_context_layer = Concatenate(axis=-1)\n",
    "        concat_context = concat_context_layer([context, decoder_outputs])\n",
    "\n",
    "        attention_dense_output_layer = Dense(attention_score_dim, activation='tanh')\n",
    "        attention_output_layer = TimeDistributed(attention_dense_output_layer)\n",
    "        attention_output = attention_output_layer(concat_context)\n",
    "        \n",
    "        \n",
    "        outputs = Dense(num_categories, activation='softmax')(attention_output)\n",
    "        outputs = Flatten()(outputs)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[inputs, decoder_inputs], outputs=outputs)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "#         encoder_model = Model(inputs=inputs, outputs=[decoder_outputs, encoder_output_states])\n",
    "#         encoder_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "#         decoder_model = Model(inputs=decoder_inputs)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make decoder inputs with dictionary '<s>'\n",
    "decoder_x_train = np.array([[1, ] for _ in range(len(_x_train))])\n",
    "decoder_x_test = np.array([[1, ] for _ in range(len(_x_test))])\n",
    "\n",
    "print(decoder_x_train.shape)\n",
    "print(decoder_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = attention_baseline(input_shape=_x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n",
    "          batch_size=256, verbose=1, epochs=100)\n",
    "loss, metrics = model.evaluate([_x_test, decoder_x_test], _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Concept - Encoder / Decoder Style (Luong Version) with CORRECTED LAST OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of last dimension is 0, then that means it is padded !\n",
    "def get_pad_index():\n",
    "    return Lambda(lambda x: K.cast(K.not_equal(K.sum(x, axis=-1, keepdims=True), 0), 'float32'))\n",
    "\n",
    "def get_last_outputs(inputs, outputs, dimension, seq_length):\n",
    "    if dimension == 2:\n",
    "        new_inputs = Reshape((seq_length, 1))(inputs)\n",
    "    else:\n",
    "        new_inputs = inputs\n",
    "    pad_index = get_pad_index()(new_inputs)\n",
    "    last_index = Lambda(lambda x: K.sum(x, axis=-2) - 1)(pad_index)\n",
    "\n",
    "    # LAST RELEVANT OUTPUT\n",
    "    # create the row index with tf.range\n",
    "    row_idx = Lambda(lambda x: tf.reshape(tf.range(tf.shape(x)[0]), (-1,1)))(last_index)\n",
    "\n",
    "    # stack with column index\n",
    "    idx = Lambda(lambda x: tf.stack([row_idx, K.cast(x, 'int32')], axis=-1))(last_index)\n",
    "    # extract the elements with gather_nd\n",
    "    last_outputs = Lambda(lambda x: tf.gather_nd(x, idx))(outputs)\n",
    "    \n",
    "    last_outputs = Reshape((latent_dim, ))(last_outputs)\n",
    "    return pad_index, last_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_dim = 128\n",
    "embedding_dim = 200\n",
    "rnn_dim = 128\n",
    "latent_dim = 128\n",
    "\n",
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "def attention_baseline2(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        encoder_inputs = Input(input_shape)\n",
    "        \n",
    "        embeded_enc = Embedding(num_words, embedding_dim)(encoder_inputs)\n",
    "#         encoder = Bidirectional(LSTM(lstm_dim, return_sequences=True, return_state=True))\n",
    "        encoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, encoder_last_output = encoder(embeded_enc)\n",
    "        \n",
    "#         pad_index, last_outputs = get_last_outputs(encoder_inputs, encoder_outputs, dimension=2, seq_length=input_shape[0])\n",
    "#         encoder_outputs = Multiply()([pad_index, encoder_outputs])\n",
    "        \n",
    "        decoder_inputs = Input((1, ))\n",
    "        embeded_dec = Embedding(1, embedding_dim)(decoder_inputs)\n",
    "        decoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, decoder_last_output = decoder(embeded_dec, initial_state=encoder_last_output)\n",
    "#         decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec)\n",
    "        \n",
    "        # Make Attention Layer\n",
    "        reapeat_d = repeat_vector(seq_length=seq_max_length, axis=2)(decoder_outputs)\n",
    "        repeat_e = repeat_vector(seq_length=1, axis=1)(encoder_outputs)\n",
    "\n",
    "        attention_concat_outputs = Concatenate()([reapeat_d, repeat_e])\n",
    "        dense1_score = Dense(attention_score_dim, activation='tanh')(attention_concat_outputs)\n",
    "        score_layer = Dense(1)(dense1_score)\n",
    "        dense2_score = Reshape((1, seq_max_length))(score_layer) # reshape to be 2 dims\n",
    "        softmax_score = Activation('softmax')(dense2_score)\n",
    "        \n",
    "        repeat_score_layer = repeat_vector(attention_score_dim, 2)\n",
    "        repeat_score = repeat_score_layer(softmax_score)\n",
    "\n",
    "        permute_e = Permute((2, 1))(encoder_outputs)\n",
    "        repeat_e_layer = repeat_vector(1, 1)\n",
    "        repeat_e = repeat_e_layer(permute_e)\n",
    "\n",
    "        attended_mat_layer = Multiply()\n",
    "        attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
    "\n",
    "        context_layer = Lambda(lambda x: K.sum(x, axis=-1),\n",
    "                                     lambda x: tuple(x[:-1]))\n",
    "        context = context_layer(attended_mat)\n",
    "\n",
    "        concat_context_layer = Concatenate(axis=-1)\n",
    "        concat_context = concat_context_layer([context, decoder_outputs])\n",
    "\n",
    "        attention_dense_output_layer = Dense(attention_score_dim, activation='tanh')\n",
    "        attention_output_layer = TimeDistributed(attention_dense_output_layer)\n",
    "        attention_output = attention_output_layer(concat_context)\n",
    "        \n",
    "        \n",
    "        outputs = Dense(num_categories, activation='softmax')(attention_output)\n",
    "        outputs = Flatten()(outputs)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "#         encoder_model = Model(inputs=inputs, outputs=[decoder_outputs, encoder_output_states])\n",
    "#         encoder_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "#         decoder_model = Model(inputs=decoder_inputs)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 1)\n",
      "(2246, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make decoder inputs with dictionary '<s>'\n",
    "decoder_x_train = np.array([[1, ] for _ in range(len(_x_train))])\n",
    "decoder_x_test = np.array([[1, ] for _ in range(len(_x_test))])\n",
    "\n",
    "print(decoder_x_train.shape)\n",
    "print(decoder_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 146)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 146, 200)     6195800     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 200)       200         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     [(None, 146, 128), ( 126336      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     [(None, 1, 128), (No 126336      embedding_9[0][0]                \n",
      "                                                                 gru_5[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1, 146, 128)  0           gru_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 146, 128)  0           gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 146, 256)  0           lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 146, 128)  32896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 146, 1)    129         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 146)       0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 146)       0           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 128, 146)     0           gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1, 128, 146)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 128, 146)  0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1, 128, 146)  0           lambda_23[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1, 128)       0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 256)       0           lambda_25[0][0]                  \n",
      "                                                                 gru_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 1, 128)       32896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 46)        5934        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 46)           0           dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,520,527\n",
      "Trainable params: 6,520,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/100\n",
      "8982/8982 [==============================] - 12s 1ms/step - loss: 2.7189 - acc: 0.3402 - val_loss: 2.2552 - val_acc: 0.3486\n",
      "Epoch 2/100\n",
      "8982/8982 [==============================] - 9s 980us/step - loss: 1.9729 - acc: 0.4254 - val_loss: 1.7487 - val_acc: 0.5548\n",
      "Epoch 3/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 1.5535 - acc: 0.6016 - val_loss: 1.5830 - val_acc: 0.6184\n",
      "Epoch 4/100\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 1.3119 - acc: 0.6679 - val_loss: 1.4883 - val_acc: 0.6514\n",
      "Epoch 5/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 1.0877 - acc: 0.7338 - val_loss: 1.4147 - val_acc: 0.6808\n",
      "Epoch 6/100\n",
      "8982/8982 [==============================] - 9s 966us/step - loss: 0.8734 - acc: 0.7890 - val_loss: 1.3525 - val_acc: 0.6892\n",
      "Epoch 7/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.7145 - acc: 0.8274 - val_loss: 1.3776 - val_acc: 0.6932\n",
      "Epoch 8/100\n",
      "8982/8982 [==============================] - 9s 961us/step - loss: 0.5986 - acc: 0.8589 - val_loss: 1.3842 - val_acc: 0.7110\n",
      "Epoch 9/100\n",
      "8982/8982 [==============================] - 9s 990us/step - loss: 0.4975 - acc: 0.8833 - val_loss: 1.3530 - val_acc: 0.7115\n",
      "Epoch 10/100\n",
      "8982/8982 [==============================] - 9s 964us/step - loss: 0.4307 - acc: 0.8986 - val_loss: 1.3839 - val_acc: 0.7146\n",
      "Epoch 11/100\n",
      "8982/8982 [==============================] - 9s 975us/step - loss: 0.3673 - acc: 0.9126 - val_loss: 1.4174 - val_acc: 0.7235\n",
      "Epoch 12/100\n",
      "8982/8982 [==============================] - 9s 981us/step - loss: 0.3180 - acc: 0.9254 - val_loss: 1.4148 - val_acc: 0.7199\n",
      "Epoch 13/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.2871 - acc: 0.9321 - val_loss: 1.4677 - val_acc: 0.7168\n",
      "Epoch 14/100\n",
      "8982/8982 [==============================] - 9s 985us/step - loss: 0.7075 - acc: 0.8961 - val_loss: 2.3874 - val_acc: 0.5209\n",
      "Epoch 15/100\n",
      "8982/8982 [==============================] - 9s 995us/step - loss: 0.5191 - acc: 0.8634 - val_loss: 2.3595 - val_acc: 0.6287\n",
      "Epoch 16/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.5157 - acc: 0.8849 - val_loss: 1.4546 - val_acc: 0.7217\n",
      "Epoch 17/100\n",
      "8982/8982 [==============================] - 9s 965us/step - loss: 0.2733 - acc: 0.9364 - val_loss: 1.4031 - val_acc: 0.7320\n",
      "Epoch 18/100\n",
      "8982/8982 [==============================] - 9s 959us/step - loss: 0.2150 - acc: 0.9443 - val_loss: 1.4700 - val_acc: 0.7315\n",
      "Epoch 19/100\n",
      "8982/8982 [==============================] - 9s 956us/step - loss: 0.1964 - acc: 0.9470 - val_loss: 1.5342 - val_acc: 0.7173\n",
      "Epoch 20/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.1839 - acc: 0.9483 - val_loss: 1.5634 - val_acc: 0.7257\n",
      "Epoch 21/100\n",
      "8982/8982 [==============================] - 9s 972us/step - loss: 0.1654 - acc: 0.9513 - val_loss: 1.5861 - val_acc: 0.7222\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.1602 - acc: 0.9525 - val_loss: 1.5851 - val_acc: 0.7244\n",
      "Epoch 23/100\n",
      "8982/8982 [==============================] - 9s 973us/step - loss: 0.1510 - acc: 0.9540 - val_loss: 1.5863 - val_acc: 0.7204\n",
      "Epoch 24/100\n",
      "8982/8982 [==============================] - 9s 998us/step - loss: 0.1399 - acc: 0.9537 - val_loss: 1.6275 - val_acc: 0.7222\n",
      "Epoch 25/100\n",
      "8982/8982 [==============================] - 9s 970us/step - loss: 0.1390 - acc: 0.9549 - val_loss: 1.6830 - val_acc: 0.7177\n",
      "Epoch 26/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.1279 - acc: 0.9549 - val_loss: 1.6455 - val_acc: 0.7164\n",
      "Epoch 27/100\n",
      "8982/8982 [==============================] - 9s 982us/step - loss: 0.1449 - acc: 0.9542 - val_loss: 1.6441 - val_acc: 0.7119\n",
      "Epoch 28/100\n",
      "8982/8982 [==============================] - 9s 968us/step - loss: 0.1336 - acc: 0.9535 - val_loss: 1.7518 - val_acc: 0.7066\n",
      "Epoch 29/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.1271 - acc: 0.9560 - val_loss: 1.6783 - val_acc: 0.7150\n",
      "Epoch 30/100\n",
      "8982/8982 [==============================] - 9s 990us/step - loss: 0.1164 - acc: 0.9555 - val_loss: 1.7270 - val_acc: 0.7110\n",
      "Epoch 31/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.1187 - acc: 0.9569 - val_loss: 1.6845 - val_acc: 0.7115\n",
      "Epoch 32/100\n",
      "8982/8982 [==============================] - 9s 990us/step - loss: 0.1095 - acc: 0.9570 - val_loss: 1.7274 - val_acc: 0.7106\n",
      "Epoch 33/100\n",
      "8982/8982 [==============================] - 9s 958us/step - loss: 0.1093 - acc: 0.9584 - val_loss: 1.7168 - val_acc: 0.7053\n",
      "Epoch 34/100\n",
      "8982/8982 [==============================] - 8s 946us/step - loss: 0.1020 - acc: 0.9576 - val_loss: 1.7850 - val_acc: 0.7057\n",
      "Epoch 35/100\n",
      "8982/8982 [==============================] - 9s 962us/step - loss: 0.0983 - acc: 0.9567 - val_loss: 1.8193 - val_acc: 0.7021\n",
      "Epoch 36/100\n",
      "8982/8982 [==============================] - 9s 973us/step - loss: 0.1000 - acc: 0.9550 - val_loss: 1.7937 - val_acc: 0.7048\n",
      "Epoch 37/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0960 - acc: 0.9586 - val_loss: 1.8262 - val_acc: 0.7021\n",
      "Epoch 38/100\n",
      "8982/8982 [==============================] - 9s 953us/step - loss: 0.0966 - acc: 0.9574 - val_loss: 1.8274 - val_acc: 0.7008\n",
      "Epoch 39/100\n",
      "8982/8982 [==============================] - 9s 965us/step - loss: 0.0957 - acc: 0.9574 - val_loss: 1.8316 - val_acc: 0.6995\n",
      "Epoch 40/100\n",
      "8982/8982 [==============================] - 9s 951us/step - loss: 0.0944 - acc: 0.9572 - val_loss: 1.8230 - val_acc: 0.7048\n",
      "Epoch 41/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0900 - acc: 0.9593 - val_loss: 1.8145 - val_acc: 0.7021\n",
      "Epoch 42/100\n",
      "8982/8982 [==============================] - 9s 951us/step - loss: 0.0937 - acc: 0.9578 - val_loss: 1.8721 - val_acc: 0.6932\n",
      "Epoch 43/100\n",
      "8982/8982 [==============================] - 9s 960us/step - loss: 0.0993 - acc: 0.9589 - val_loss: 1.8418 - val_acc: 0.7012\n",
      "Epoch 44/100\n",
      "8982/8982 [==============================] - 9s 956us/step - loss: 0.0927 - acc: 0.9579 - val_loss: 1.8724 - val_acc: 0.6990\n",
      "Epoch 45/100\n",
      "8982/8982 [==============================] - 8s 943us/step - loss: 0.0877 - acc: 0.9582 - val_loss: 1.9041 - val_acc: 0.6950\n",
      "Epoch 46/100\n",
      "8982/8982 [==============================] - 9s 958us/step - loss: 0.0883 - acc: 0.9569 - val_loss: 1.9593 - val_acc: 0.6901\n",
      "Epoch 47/100\n",
      "8982/8982 [==============================] - 9s 955us/step - loss: 0.0879 - acc: 0.9569 - val_loss: 1.9852 - val_acc: 0.6932\n",
      "Epoch 48/100\n",
      "8982/8982 [==============================] - 9s 979us/step - loss: 0.0858 - acc: 0.9579 - val_loss: 1.9154 - val_acc: 0.6990\n",
      "Epoch 49/100\n",
      "8982/8982 [==============================] - 9s 978us/step - loss: 0.0844 - acc: 0.9590 - val_loss: 1.9365 - val_acc: 0.6950\n",
      "Epoch 50/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0835 - acc: 0.9569 - val_loss: 2.0067 - val_acc: 0.6950\n",
      "Epoch 51/100\n",
      "8982/8982 [==============================] - 9s 981us/step - loss: 0.0835 - acc: 0.9571 - val_loss: 1.9970 - val_acc: 0.6972\n",
      "Epoch 52/100\n",
      "8982/8982 [==============================] - 9s 964us/step - loss: 0.0878 - acc: 0.9587 - val_loss: 1.9487 - val_acc: 0.6990\n",
      "Epoch 53/100\n",
      "8982/8982 [==============================] - 9s 960us/step - loss: 0.0825 - acc: 0.9590 - val_loss: 2.0056 - val_acc: 0.6919\n",
      "Epoch 54/100\n",
      "8982/8982 [==============================] - 9s 962us/step - loss: 0.0838 - acc: 0.9567 - val_loss: 1.9765 - val_acc: 0.6932\n",
      "Epoch 55/100\n",
      "8982/8982 [==============================] - 9s 977us/step - loss: 0.0795 - acc: 0.9559 - val_loss: 2.0104 - val_acc: 0.6946\n",
      "Epoch 56/100\n",
      "8982/8982 [==============================] - 9s 979us/step - loss: 0.0780 - acc: 0.9575 - val_loss: 2.0627 - val_acc: 0.6892\n",
      "Epoch 57/100\n",
      "8982/8982 [==============================] - 9s 965us/step - loss: 0.0772 - acc: 0.9594 - val_loss: 2.0506 - val_acc: 0.6937\n",
      "Epoch 58/100\n",
      "8982/8982 [==============================] - 9s 986us/step - loss: 0.0764 - acc: 0.9604 - val_loss: 2.0253 - val_acc: 0.6910\n",
      "Epoch 59/100\n",
      "8982/8982 [==============================] - 9s 956us/step - loss: 0.0764 - acc: 0.9575 - val_loss: 2.0435 - val_acc: 0.6950\n",
      "Epoch 60/100\n",
      "8982/8982 [==============================] - 9s 960us/step - loss: 0.0843 - acc: 0.9601 - val_loss: 2.0682 - val_acc: 0.6879\n",
      "Epoch 61/100\n",
      "8982/8982 [==============================] - 9s 968us/step - loss: 0.0787 - acc: 0.9588 - val_loss: 2.0231 - val_acc: 0.6915\n",
      "Epoch 62/100\n",
      "8982/8982 [==============================] - 9s 960us/step - loss: 0.0750 - acc: 0.9593 - val_loss: 2.0402 - val_acc: 0.6888\n",
      "Epoch 63/100\n",
      "8982/8982 [==============================] - 9s 959us/step - loss: 0.0715 - acc: 0.9578 - val_loss: 2.0793 - val_acc: 0.6937\n",
      "Epoch 64/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.0715 - acc: 0.9601 - val_loss: 2.1144 - val_acc: 0.6910\n",
      "Epoch 65/100\n",
      "8982/8982 [==============================] - 9s 963us/step - loss: 0.0699 - acc: 0.9594 - val_loss: 2.1522 - val_acc: 0.6857\n",
      "Epoch 66/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.0729 - acc: 0.9579 - val_loss: 2.0580 - val_acc: 0.6915\n",
      "Epoch 67/100\n",
      "8982/8982 [==============================] - 9s 959us/step - loss: 0.0778 - acc: 0.9584 - val_loss: 2.0904 - val_acc: 0.6874\n",
      "Epoch 68/100\n",
      "8982/8982 [==============================] - 9s 965us/step - loss: 0.0785 - acc: 0.9599 - val_loss: 2.0906 - val_acc: 0.6932\n",
      "Epoch 69/100\n",
      "8982/8982 [==============================] - 9s 961us/step - loss: 0.0826 - acc: 0.9568 - val_loss: 2.1054 - val_acc: 0.6866\n",
      "Epoch 70/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.0754 - acc: 0.9577 - val_loss: 2.1318 - val_acc: 0.6843\n",
      "Epoch 71/100\n",
      "8982/8982 [==============================] - 9s 960us/step - loss: 0.0761 - acc: 0.9587 - val_loss: 2.1308 - val_acc: 0.6857\n",
      "Epoch 72/100\n",
      "8982/8982 [==============================] - 9s 962us/step - loss: 0.0724 - acc: 0.9588 - val_loss: 2.1534 - val_acc: 0.6812\n",
      "Epoch 73/100\n",
      "8982/8982 [==============================] - 9s 966us/step - loss: 0.0711 - acc: 0.9588 - val_loss: 2.1530 - val_acc: 0.6874\n",
      "Epoch 74/100\n",
      "8982/8982 [==============================] - 9s 955us/step - loss: 0.0712 - acc: 0.9593 - val_loss: 2.2355 - val_acc: 0.6781\n",
      "Epoch 75/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.0724 - acc: 0.9587 - val_loss: 2.2210 - val_acc: 0.6768\n",
      "Epoch 76/100\n",
      "8982/8982 [==============================] - 9s 966us/step - loss: 0.0690 - acc: 0.9584 - val_loss: 2.2008 - val_acc: 0.6794\n",
      "Epoch 77/100\n",
      "8982/8982 [==============================] - 9s 969us/step - loss: 0.0685 - acc: 0.9581 - val_loss: 2.2383 - val_acc: 0.6839\n",
      "Epoch 78/100\n",
      "8982/8982 [==============================] - 9s 964us/step - loss: 0.0718 - acc: 0.9586 - val_loss: 2.2640 - val_acc: 0.6723\n",
      "Epoch 79/100\n",
      "8982/8982 [==============================] - 9s 964us/step - loss: 0.0688 - acc: 0.9581 - val_loss: 2.2364 - val_acc: 0.6776\n",
      "Epoch 80/100\n",
      "8982/8982 [==============================] - 9s 967us/step - loss: 0.0656 - acc: 0.9593 - val_loss: 2.2716 - val_acc: 0.6785\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0670 - acc: 0.9562 - val_loss: 2.2573 - val_acc: 0.6785\n",
      "Epoch 82/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0679 - acc: 0.9568 - val_loss: 2.3002 - val_acc: 0.6794\n",
      "Epoch 83/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0690 - acc: 0.9582 - val_loss: 2.2474 - val_acc: 0.6768\n",
      "Epoch 84/100\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.0687 - acc: 0.9595 - val_loss: 2.2809 - val_acc: 0.6781\n",
      "Epoch 85/100\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.0683 - acc: 0.9600 - val_loss: 2.3378 - val_acc: 0.6772\n",
      "Epoch 86/100\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.0673 - acc: 0.9584 - val_loss: 2.3159 - val_acc: 0.6817\n",
      "Epoch 87/100\n",
      "8982/8982 [==============================] - 9s 987us/step - loss: 0.0698 - acc: 0.9593 - val_loss: 2.2522 - val_acc: 0.6799\n",
      "Epoch 88/100\n",
      "8982/8982 [==============================] - 9s 971us/step - loss: 0.0755 - acc: 0.9569 - val_loss: 2.2370 - val_acc: 0.6808\n",
      "Epoch 89/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0709 - acc: 0.9576 - val_loss: 2.3319 - val_acc: 0.6785\n",
      "Epoch 90/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0693 - acc: 0.9619 - val_loss: 2.3587 - val_acc: 0.6745\n",
      "Epoch 91/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0693 - acc: 0.9568 - val_loss: 2.3273 - val_acc: 0.6821\n",
      "Epoch 92/100\n",
      "8982/8982 [==============================] - 9s 978us/step - loss: 0.0664 - acc: 0.9572 - val_loss: 2.3124 - val_acc: 0.6803\n",
      "Epoch 93/100\n",
      "8982/8982 [==============================] - 9s 962us/step - loss: 0.0669 - acc: 0.9605 - val_loss: 2.2697 - val_acc: 0.6736\n",
      "Epoch 94/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0658 - acc: 0.9596 - val_loss: 2.3762 - val_acc: 0.6736\n",
      "Epoch 95/100\n",
      "8982/8982 [==============================] - 9s 1ms/step - loss: 0.0672 - acc: 0.9595 - val_loss: 2.3825 - val_acc: 0.6705\n",
      "Epoch 96/100\n",
      "8982/8982 [==============================] - 9s 976us/step - loss: 0.0663 - acc: 0.9587 - val_loss: 2.3988 - val_acc: 0.6710\n",
      "Epoch 97/100\n",
      "8982/8982 [==============================] - 9s 970us/step - loss: 0.0651 - acc: 0.9613 - val_loss: 2.4757 - val_acc: 0.6679\n",
      "Epoch 98/100\n",
      "8982/8982 [==============================] - 9s 974us/step - loss: 0.0652 - acc: 0.9600 - val_loss: 2.3894 - val_acc: 0.6696\n",
      "Epoch 99/100\n",
      "8982/8982 [==============================] - 9s 979us/step - loss: 0.0628 - acc: 0.9593 - val_loss: 2.3981 - val_acc: 0.6768\n",
      "Epoch 100/100\n",
      "8982/8982 [==============================] - 9s 957us/step - loss: 0.0615 - acc: 0.9605 - val_loss: 2.4313 - val_acc: 0.6719\n",
      "2246/2246 [==============================] - 1s 347us/step\n",
      "0.6718610868534656\n"
     ]
    }
   ],
   "source": [
    "model = attention_baseline2(input_shape=_x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n",
    "          batch_size=256, verbose=1, epochs=100)\n",
    "loss, metrics = model.evaluate([_x_test, decoder_x_test], _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_dim = 128\n",
    "embedding_dim = 200\n",
    "rnn_dim = 128\n",
    "latent_dim = 128\n",
    "\n",
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "def attention_baseline3(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        encoder_inputs = Input(input_shape)\n",
    "        \n",
    "        embeded_enc = Embedding(num_words, embedding_dim)(encoder_inputs)\n",
    "#         encoder = Bidirectional(LSTM(lstm_dim, return_sequences=True, return_state=True))\n",
    "        encoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, encoder_last_output = encoder(embeded_enc)\n",
    "        \n",
    "        pad_index, last_outputs = get_last_outputs(encoder_inputs, encoder_outputs, dimension=2, seq_length=input_shape[0])\n",
    "        encoder_outputs = Multiply()([pad_index, encoder_outputs])\n",
    "        \n",
    "        decoder_inputs = Input((1, ))\n",
    "        embeded_dec = Embedding(1, embedding_dim)(decoder_inputs)\n",
    "        decoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, decoder_last_output = decoder(embeded_dec, initial_state=last_outputs)\n",
    "#         decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec)\n",
    "        \n",
    "        # Make Attention Layer\n",
    "        reapeat_d = repeat_vector(seq_length=seq_max_length, axis=2)(decoder_outputs)\n",
    "        repeat_e = repeat_vector(seq_length=1, axis=1)(encoder_outputs)\n",
    "\n",
    "        attention_concat_outputs = Concatenate()([reapeat_d, repeat_e])\n",
    "        dense1_score = Dense(attention_score_dim, activation='tanh')(attention_concat_outputs)\n",
    "        score_layer = Dense(1)(dense1_score)\n",
    "        dense2_score = Reshape((1, seq_max_length))(score_layer) # reshape to be 2 dims\n",
    "        softmax_score = Activation('softmax')(dense2_score)\n",
    "        \n",
    "        repeat_score_layer = repeat_vector(attention_score_dim, 2)\n",
    "        repeat_score = repeat_score_layer(softmax_score)\n",
    "\n",
    "        permute_e = Permute((2, 1))(encoder_outputs)\n",
    "        repeat_e_layer = repeat_vector(1, 1)\n",
    "        repeat_e = repeat_e_layer(permute_e)\n",
    "\n",
    "        attended_mat_layer = Multiply()\n",
    "        attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
    "\n",
    "        context_layer = Lambda(lambda x: K.sum(x, axis=-1),\n",
    "                                     lambda x: tuple(x[:-1]))\n",
    "        context = context_layer(attended_mat)\n",
    "\n",
    "        concat_context_layer = Concatenate(axis=-1)\n",
    "        concat_context = concat_context_layer([context, decoder_outputs])\n",
    "\n",
    "        attention_dense_output_layer = Dense(attention_score_dim, activation='tanh')\n",
    "        attention_output_layer = TimeDistributed(attention_dense_output_layer)\n",
    "        attention_output = attention_output_layer(concat_context)\n",
    "        \n",
    "        \n",
    "        outputs = Dense(num_categories, activation='softmax')(attention_output)\n",
    "        outputs = Flatten()(outputs)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "#         encoder_model = Model(inputs=inputs, outputs=[decoder_outputs, encoder_output_states])\n",
    "#         encoder_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "#         decoder_model = Model(inputs=decoder_inputs)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 1)\n",
      "(2246, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make decoder inputs with dictionary '<s>'\n",
    "decoder_x_train = np.array([[1, ] for _ in range(len(_x_train))])\n",
    "decoder_x_test = np.array([[1, ] for _ in range(len(_x_test))])\n",
    "\n",
    "print(decoder_x_train.shape)\n",
    "print(decoder_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 146)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 146, 200)     6195800     input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     [(None, 146, 128), ( 126336      embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1, 128)       0           gru_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 146, 1)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 200)       200         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 128)          0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 146, 1)       0           reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     [(None, 1, 128), (No 126336      embedding_11[0][0]               \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 146, 128)     0           lambda_26[0][0]                  \n",
      "                                                                 gru_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1, 146, 128)  0           gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1, 146, 128)  0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 146, 256)  0           lambda_31[0][0]                  \n",
      "                                                                 lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 146, 128)  32896       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 146, 1)    129         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 146)       0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 146)       0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 146)     0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1, 128, 146)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1, 128, 146)  0           permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 1, 128, 146)  0           lambda_33[0][0]                  \n",
      "                                                                 lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1, 128)       0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 256)       0           lambda_35[0][0]                  \n",
      "                                                                 gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 1, 128)       32896       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 46)        5934        time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 46)           0           dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,520,527\n",
      "Trainable params: 6,520,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/100\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 3.1533 - acc: 0.2505 - val_loss: 2.2805 - val_acc: 0.3486\n",
      "Epoch 2/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 1.9750 - acc: 0.4625 - val_loss: 1.7956 - val_acc: 0.5280\n",
      "Epoch 3/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 1.6366 - acc: 0.5701 - val_loss: 1.6499 - val_acc: 0.5717\n",
      "Epoch 4/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 1.4836 - acc: 0.6106 - val_loss: 1.5829 - val_acc: 0.6175\n",
      "Epoch 5/100\n",
      "8982/8982 [==============================] - 14s 2ms/step - loss: 1.3559 - acc: 0.6468 - val_loss: 1.5919 - val_acc: 0.6287\n",
      "Epoch 6/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 1.2110 - acc: 0.6894 - val_loss: 1.6435 - val_acc: 0.6340\n",
      "Epoch 7/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 1.0874 - acc: 0.7224 - val_loss: 1.6009 - val_acc: 0.6496\n",
      "Epoch 8/100\n",
      "8982/8982 [==============================] - 13s 2ms/step - loss: 0.9728 - acc: 0.7504 - val_loss: 1.6230 - val_acc: 0.6438\n",
      "Epoch 9/100\n",
      "8982/8982 [==============================] - 14s 2ms/step - loss: 0.8847 - acc: 0.7767 - val_loss: 1.7312 - val_acc: 0.6175\n",
      "Epoch 10/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.7929 - acc: 0.7997 - val_loss: 1.6776 - val_acc: 0.6523\n",
      "Epoch 11/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.7199 - acc: 0.8210 - val_loss: 1.6634 - val_acc: 0.6634\n",
      "Epoch 12/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.7050 - acc: 0.8357 - val_loss: 1.7408 - val_acc: 0.6447\n",
      "Epoch 13/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.6541 - acc: 0.8428 - val_loss: 1.7122 - val_acc: 0.6496\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.7953 - acc: 0.7984 - val_loss: 1.6892 - val_acc: 0.6416\n",
      "Epoch 15/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.6662 - acc: 0.8302 - val_loss: 1.6493 - val_acc: 0.6607\n",
      "Epoch 16/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.5349 - acc: 0.8651 - val_loss: 1.6398 - val_acc: 0.6696\n",
      "Epoch 17/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.4422 - acc: 0.8949 - val_loss: 1.6592 - val_acc: 0.6768\n",
      "Epoch 18/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.3991 - acc: 0.9061 - val_loss: 1.6912 - val_acc: 0.6759\n",
      "Epoch 19/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.3714 - acc: 0.9142 - val_loss: 1.7640 - val_acc: 0.6665\n",
      "Epoch 20/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.3390 - acc: 0.9223 - val_loss: 1.7663 - val_acc: 0.6652\n",
      "Epoch 21/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.3031 - acc: 0.9310 - val_loss: 1.7812 - val_acc: 0.6705\n",
      "Epoch 22/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2731 - acc: 0.9369 - val_loss: 1.8298 - val_acc: 0.6665\n",
      "Epoch 23/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2525 - acc: 0.9389 - val_loss: 1.8536 - val_acc: 0.6656\n",
      "Epoch 24/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.3632 - acc: 0.9154 - val_loss: 1.8753 - val_acc: 0.6594\n",
      "Epoch 25/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2971 - acc: 0.9271 - val_loss: 1.8019 - val_acc: 0.6589\n",
      "Epoch 26/100\n",
      "8982/8982 [==============================] - 14s 2ms/step - loss: 0.2387 - acc: 0.9414 - val_loss: 1.8609 - val_acc: 0.6625\n",
      "Epoch 27/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2084 - acc: 0.9472 - val_loss: 1.8689 - val_acc: 0.6665\n",
      "Epoch 28/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2070 - acc: 0.9472 - val_loss: 1.8924 - val_acc: 0.6634\n",
      "Epoch 29/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.2034 - acc: 0.9489 - val_loss: 1.8913 - val_acc: 0.6719\n",
      "Epoch 30/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1836 - acc: 0.9472 - val_loss: 1.9437 - val_acc: 0.6616\n",
      "Epoch 31/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1801 - acc: 0.9499 - val_loss: 1.9438 - val_acc: 0.6656\n",
      "Epoch 32/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1686 - acc: 0.9511 - val_loss: 1.9724 - val_acc: 0.6598\n",
      "Epoch 33/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1609 - acc: 0.9530 - val_loss: 1.9989 - val_acc: 0.6549\n",
      "Epoch 34/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1538 - acc: 0.9528 - val_loss: 2.0229 - val_acc: 0.6621\n",
      "Epoch 35/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1484 - acc: 0.9539 - val_loss: 2.0270 - val_acc: 0.6665\n",
      "Epoch 36/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1394 - acc: 0.9560 - val_loss: 2.0866 - val_acc: 0.6581\n",
      "Epoch 37/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1452 - acc: 0.9554 - val_loss: 2.0701 - val_acc: 0.6603\n",
      "Epoch 38/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1364 - acc: 0.9549 - val_loss: 2.1158 - val_acc: 0.6541\n",
      "Epoch 39/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1405 - acc: 0.9535 - val_loss: 2.1562 - val_acc: 0.6581\n",
      "Epoch 40/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1326 - acc: 0.9554 - val_loss: 2.1586 - val_acc: 0.6523\n",
      "Epoch 41/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1297 - acc: 0.9566 - val_loss: 2.1579 - val_acc: 0.6576\n",
      "Epoch 42/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1477 - acc: 0.9520 - val_loss: 2.1601 - val_acc: 0.6496\n",
      "Epoch 43/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1306 - acc: 0.9540 - val_loss: 2.1211 - val_acc: 0.6567\n",
      "Epoch 44/100\n",
      "8982/8982 [==============================] - 13s 1ms/step - loss: 0.1266 - acc: 0.9571 - val_loss: 2.1318 - val_acc: 0.6563\n",
      "Epoch 45/100\n",
      "2560/8982 [=======>......................] - ETA: 8s - loss: 0.1196 - acc: 0.9605"
     ]
    }
   ],
   "source": [
    "model = attention_baseline3(input_shape=_x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n",
    "          batch_size=256, verbose=1, epochs=100)\n",
    "loss, metrics = model.evaluate([_x_test, decoder_x_test], _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_dim = 128\n",
    "embedding_dim = 200\n",
    "rnn_dim = 128\n",
    "latent_dim = 128\n",
    "\n",
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "def attention_baseline4(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        encoder_inputs = Input(input_shape)\n",
    "        \n",
    "        embeded_enc = Embedding(num_words, embedding_dim)(encoder_inputs)\n",
    "#         encoder = Bidirectional(LSTM(lstm_dim, return_sequences=True, return_state=True))\n",
    "        encoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, encoder_last_output = encoder(embeded_enc)\n",
    "        \n",
    "        pad_index, last_outputs = get_last_outputs(encoder_inputs, encoder_outputs, dimension=2, seq_length=input_shape[0])\n",
    "#         encoder_outputs = Multiply()([pad_index, encoder_outputs])\n",
    "        \n",
    "        decoder_inputs = Input((1, ))\n",
    "        embeded_dec = Embedding(1, embedding_dim)(decoder_inputs)\n",
    "        decoder = GRU(rnn_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, decoder_last_output = decoder(embeded_dec, initial_state=last_outputs)\n",
    "#         decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec)\n",
    "        \n",
    "        # Make Attention Layer\n",
    "        reapeat_d = repeat_vector(seq_length=seq_max_length, axis=2)(decoder_outputs)\n",
    "        repeat_e = repeat_vector(seq_length=1, axis=1)(encoder_outputs)\n",
    "\n",
    "        attention_concat_outputs = Concatenate()([reapeat_d, repeat_e])\n",
    "        dense1_score = Dense(attention_score_dim, activation='tanh')(attention_concat_outputs)\n",
    "        score_layer = Dense(1)(dense1_score)\n",
    "        dense2_score = Reshape((1, seq_max_length))(score_layer) # reshape to be 2 dims\n",
    "        softmax_score = Activation('softmax')(dense2_score)\n",
    "        \n",
    "        repeat_score_layer = repeat_vector(attention_score_dim, 2)\n",
    "        repeat_score = repeat_score_layer(softmax_score)\n",
    "\n",
    "        permute_e = Permute((2, 1))(encoder_outputs)\n",
    "        repeat_e_layer = repeat_vector(1, 1)\n",
    "        repeat_e = repeat_e_layer(permute_e)\n",
    "\n",
    "        attended_mat_layer = Multiply()\n",
    "        attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
    "\n",
    "        context_layer = Lambda(lambda x: K.sum(x, axis=-1),\n",
    "                                     lambda x: tuple(x[:-1]))\n",
    "        context = context_layer(attended_mat)\n",
    "\n",
    "        concat_context_layer = Concatenate(axis=-1)\n",
    "        concat_context = concat_context_layer([context, decoder_outputs])\n",
    "\n",
    "        attention_dense_output_layer = Dense(attention_score_dim, activation='tanh')\n",
    "        attention_output_layer = TimeDistributed(attention_dense_output_layer)\n",
    "        attention_output = attention_output_layer(concat_context)\n",
    "        \n",
    "        \n",
    "        outputs = Dense(num_categories, activation='softmax')(attention_output)\n",
    "        outputs = Flatten()(outputs)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "#         encoder_model = Model(inputs=inputs, outputs=[decoder_outputs, encoder_output_states])\n",
    "#         encoder_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "#         decoder_model = Model(inputs=decoder_inputs)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make decoder inputs with dictionary '<s>'\n",
    "decoder_x_train = np.array([[1, ] for _ in range(len(_x_train))])\n",
    "decoder_x_test = np.array([[1, ] for _ in range(len(_x_test))])\n",
    "\n",
    "print(decoder_x_train.shape)\n",
    "print(decoder_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = attention_baseline4(input_shape=_x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n",
    "          batch_size=256, verbose=1, epochs=100)\n",
    "loss, metrics = model.evaluate([_x_test, decoder_x_test], _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luong, My try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_dim = 128\n",
    "embedding_dim = 200\n",
    "lstm_dim = 128\n",
    "\n",
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "def attention_baseline2(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        inputs = Input(input_shape)\n",
    "        embeded_enc = Embedding(num_words, embedding_dim)(inputs)\n",
    "#         encoder = Bidirectional(LSTM(lstm_dim, return_sequences=True, return_state=True))\n",
    "        encoder = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder(embeded_enc)\n",
    "        encoder_output_states = [encoder_state_h, encoder_state_c]\n",
    "        \n",
    "        decoder_inputs = Input((1, ))\n",
    "        embeded_dec = Embedding(1, embedding_dim)(decoder_inputs)\n",
    "        decoder = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec, initial_state=encoder_output_states)\n",
    "        decoder_output_states = [decoder_state_h, encoder_state_c]\n",
    "#         decoder_outputs, decoder_state_h, encoder_state_c = decoder(embeded_dec)\n",
    "        \n",
    "        # Make Attention Layer\n",
    "        reapeat_d = repeat_vector(seq_length=seq_max_length, axis=2)(decoder_output_states)\n",
    "        repeat_e = repeat_vector(seq_length=1, axis=1)(encoder_output_states)\n",
    "\n",
    "        attention_concat_outputs = Concatenate()([reapeat_d, repeat_e])\n",
    "        dense1_score = Dense(attention_score_dim, activation='tanh')(attention_concat_outputs)\n",
    "        score_layer = Dense(1)(dense1_score)\n",
    "        dense2_score = Reshape((1, seq_max_length))(score_layer) # reshape to be 2 dims\n",
    "        softmax_score = Activation('softmax')(dense2_score)\n",
    "        \n",
    "        # Context Vector\n",
    "        repeat_score_layer = repeat_vector(attention_score_dim, 2)\n",
    "        repeat_score = repeat_score_layer(softmax_score)\n",
    "\n",
    "        permute_e = Permute((2, 1))(encoder_output_states)\n",
    "        repeat_e_layer = repeat_vector(1, 1)\n",
    "        repeat_e = repeat_e_layer(permute_e)\n",
    "\n",
    "        attended_mat_layer = Multiply()\n",
    "        attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
    "\n",
    "        context_layer = Lambda(lambda x: K.sum(x, axis=-1))\n",
    "        context = context_layer(attended_mat)\n",
    "\n",
    "        concat_context_layer = Concatenate(axis=-1)\n",
    "        concat_context = concat_context_layer([context, decoder_output_states])\n",
    "\n",
    "        attention_dense_output_layer = Dense(attention_score_dim, activation='tanh')\n",
    "#         attention_output_layer = TimeDistributed(attention_dense_output_layer)\n",
    "        attention_output = attention_dense_output_layer(concat_context)\n",
    "        \n",
    "        \n",
    "        outputs = Dense(num_categories, activation='softmax')(attention_output)\n",
    "        outputs = Flatten()(outputs)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[inputs, decoder_inputs], outputs=outputs)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "#         encoder_model = Model(inputs=inputs, outputs=[decoder_outputs, encoder_output_states])\n",
    "#         encoder_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "#         decoder_model = Model(inputs=decoder_inputs)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 1)\n",
      "(2246, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make decoder inputs with dictionary '<s>'\n",
    "decoder_x_train = np.array([[1, ] for _ in range(len(_x_train))])\n",
    "decoder_x_test = np.array([[1, ] for _ in range(len(_x_test))])\n",
    "\n",
    "print(decoder_x_train.shape)\n",
    "print(decoder_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 146)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 146, 200)     6195800     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 200)       200         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 146, 128), ( 168448      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 1, 128), (No 168448      embedding_7[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 146, 128)  0           lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 146, 128)  0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 146, 256)  0           lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 146, 128)  32896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 146, 1)    129         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 146)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 146)       0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 128, 146)     0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 128, 146)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 128, 146)  0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1, 128, 146)  0           lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 128)       0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 256)       0           lambda_15[0][0]                  \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 1, 128)       32896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 46)        5934        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 46)           0           dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,604,751\n",
      "Trainable params: 6,604,751\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/30\n",
      "8982/8982 [==============================] - 14s 2ms/step - loss: 2.7016 - acc: 0.3280 - val_loss: 2.1690 - val_acc: 0.3611\n",
      "Epoch 2/30\n",
      "5120/8982 [================>.............] - ETA: 4s - loss: 1.9764 - acc: 0.4254"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-af6cc94f1592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n\u001b[1;32m----> 4\u001b[1;33m           batch_size=256, verbose=1, epochs=30)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_x_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_x_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_y_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = attention_baseline(input_shape=_x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=[_x_train, decoder_x_train], y=_y_train, validation_data=([_x_test, decoder_x_test], _y_test), \n",
    "          batch_size=256, verbose=1, epochs=30)\n",
    "loss, metrics = model.evaluate([_x_test, decoder_x_test], _y_test, batch_size=256)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dwl_QnW2QXu4"
   },
   "source": [
    "# Attention Conecept without decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "470038Y1zK91"
   },
   "outputs": [],
   "source": [
    "def attention_baseline(input_shape):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        # create model\n",
    "        #     model = Model()\n",
    "        inputs = Input(input_shape) # sequence length\n",
    "        embeded_seq = Embedding(num_words, embedding_dim)(inputs) # sequence length x 100\n",
    "        lstm = Bidirectional(LSTM(lstm_dim, return_sequences=True))(embeded_seq)\n",
    "        attention_probs = Dense(256, activation='softmax')(lstm)\n",
    "        attention_mul = multiply([lstm, attention_probs])\n",
    "\n",
    "        f = Flatten()(attention_mul) \n",
    "        f = Dense(64)(f)\n",
    "\n",
    "        y = Dense(46, activation='sigmoid')(f)\n",
    "        model = Model(inputs=i, outputs=y)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1513
    },
    "colab_type": "code",
    "id": "B6J-MCV-Q-zT",
    "outputId": "e174bdb6-9494-44f6-dc04-74bb4acb87c5"
   },
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "# estimator = KerasClassifier(build_fn=create_baseline, epochs=30, batch_size=512, verbose=1)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(estimator, _x_train, y_train, cv=kfold)\n",
    "# print(estimator.summary())\n",
    "model = attention_baseline(input_shape=x_train.shape[1:])\n",
    "print(model.summary())\n",
    "model.fit(x=_x_train, y=_y_train, validation_split=0.1, batch_size=512, verbose=1, epochs=30)\n",
    "loss, metrics = model.evaluate(_x_test, _y_test, batch_size=512)\n",
    "print(metrics)\n",
    "# results = model.predict(_x_test, y_test, batch_size=512)\n",
    "\n",
    "# print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JY-hEXke_PK"
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "  TIME_STEPS = 200\n",
    "  # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "  input_dim = int(inputs.shape[2])\n",
    "  a = Permute((2, 1))(inputs)\n",
    "  a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "  a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "#   if SINGLE_ATTENTION_VECTOR:\n",
    "#       a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "#       a = RepeatVector(input_dim)(a)\n",
    "  a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "#   output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "  output_attention_mul = multiply([inputs, a_probs])\n",
    "  return output_attention_mul\n",
    "\n",
    "\n",
    "def model_attention_applied_after_lstm(input_shape):\n",
    "  with K.tf.device('/gpu:0'):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    embeded_seq = Embedding(30979, 100)(inputs) # sequence length x 100\n",
    "    lstm_units = 128\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(embeded_seq)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(46, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1618
    },
    "colab_type": "code",
    "id": "S81phqele_TC",
    "outputId": "6a3780cd-b2a7-45d3-993f-3eba8475c441"
   },
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "# estimator = KerasClassifier(build_fn=create_baseline, epochs=30, batch_size=512, verbose=1)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(estimator, _x_train, y_train, cv=kfold)\n",
    "# print(estimator.summary())\n",
    "model = model_attention_applied_after_lstm(input_shape=(200, ))\n",
    "print(model.summary())\n",
    "model.fit(x=_x_train, y=_y_train, validation_split=0.1, batch_size=512, verbose=1, epochs=30)\n",
    "loss, metrics = model.evaluate(_x_test, _y_test, batch_size=512)\n",
    "print(metrics)\n",
    "# results = model.predict(_x_test, y_test, batch_size=512)\n",
    "\n",
    "# print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uq1hvJVMuo5m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjCWA5zau3da"
   },
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJPiF64yupBx"
   },
   "outputs": [],
   "source": [
    "def seq2seq_baseline():\n",
    "  with K.tf.device('/gpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, input_shape=(n_timesteps_in, n_features)))\n",
    "    model.add(RepeatVector(n_timesteps_in))\n",
    "    model.add(LSTM(150, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVKB2hGOwI6t"
   },
   "source": [
    "# Attention Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWyrNN42upEi"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.engine import InputSpec\n",
    " \n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    " \n",
    "\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                            input_dim=None, output_dim=None,\n",
    "                            timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        w: weight matrix.\n",
    "        b: optional bias vector.\n",
    "        dropout: wether to apply dropout (same dropout mask\n",
    "            for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "    return x\n",
    "\n",
    "class AttentionDecoder(Recurrent):\n",
    " \n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 return_probabilities=False,\n",
    "                 name='AttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states\n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    " \n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
    "            \"Neural machine translation by jointly learning to align and translate.\"\n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    " \n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    " \n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    " \n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    " \n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    " \n",
    "        if self.stateful:\n",
    "            super(AttentionDecoder, self).reset_states()\n",
    " \n",
    "        self.states = [None, None]  # y, s\n",
    " \n",
    "        \"\"\"\n",
    "            Matrices for creating the context vector\n",
    "        \"\"\"\n",
    " \n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the r (reset) gate\n",
    "        \"\"\"\n",
    "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_r = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_r',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    " \n",
    "        \"\"\"\n",
    "            Matrices for the z (update) gate\n",
    "        \"\"\"\n",
    "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_z = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_z',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the proposal\n",
    "        \"\"\"\n",
    "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_p = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_p',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for making the final prediction vector\n",
    "        \"\"\"\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    " \n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    " \n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    " \n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    " \n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    " \n",
    "        return super(AttentionDecoder, self).call(x)\n",
    " \n",
    "    def get_initial_state(self, inputs):\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    " \n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    " \n",
    "        return [y0, s0]\n",
    " \n",
    "    def step(self, x, states):\n",
    " \n",
    "        ytm, stm = states\n",
    " \n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        _stm = K.repeat(stm, self.timesteps)\n",
    " \n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        _Wxstm = K.dot(_stm, self.W_a)\n",
    " \n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.exp(et)\n",
    "        at_sum = K.sum(at, axis=1)\n",
    "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
    "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
    " \n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        # ~~~> calculate new hidden state\n",
    "        # first calculate the \"r\" gate:\n",
    " \n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_r)\n",
    "            + K.dot(stm, self.U_r)\n",
    "            + K.dot(context, self.C_r)\n",
    "            + self.b_r)\n",
    " \n",
    "        # now calculate the \"z\" gate\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_z)\n",
    "            + K.dot(stm, self.U_z)\n",
    "            + K.dot(context, self.C_z)\n",
    "            + self.b_z)\n",
    " \n",
    "        # calculate the proposal hidden state:\n",
    "        s_tp = activations.tanh(\n",
    "            K.dot(ytm, self.W_p)\n",
    "            + K.dot((rt * stm), self.U_p)\n",
    "            + K.dot(context, self.C_p)\n",
    "            + self.b_p)\n",
    " \n",
    "        # new hidden state:\n",
    "        st = (1-zt)*stm + zt * s_tp\n",
    " \n",
    "        yt = activations.softmax(\n",
    "            K.dot(ytm, self.W_o)\n",
    "            + K.dot(stm, self.U_o)\n",
    "            + K.dot(context, self.C_o)\n",
    "            + self.b_o)\n",
    " \n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, st]\n",
    "        else:\n",
    "            return yt, [yt, st]\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    " \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super(AttentionDecoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESRjVjAVupHM"
   },
   "outputs": [],
   "source": [
    "def seq2seq_attention(n_timesteps_in):\n",
    "  with K.tf.device('/gpu:0'):\n",
    "    n_features = 100\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(30979, n_features))\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps_in, n_features), return_sequences=True))\n",
    "    model.add(AttentionDecoder(128, n_features))\n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(46))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2275
    },
    "colab_type": "code",
    "id": "JSrREP0AupKU",
    "outputId": "0144b1b6-a693-47a9-dcc9-7c498a6faabd"
   },
   "outputs": [],
   "source": [
    "model = seq2seq_attention(200)\n",
    "print(model.summary())\n",
    "model.fit(x=_x_train, y=_y_train, validation_split=0.1, batch_size=512, verbose=1, epochs=30)\n",
    "loss, metrics = model.evaluate(_x_test, _y_test, batch_size=512)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgoDn9fPizbP"
   },
   "outputs": [],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=30, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, _x_train, y_train, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jv0TEnqizdz"
   },
   "outputs": [],
   "source": [
    "loss, metrics = estimator.fit(_x_test, y_test, batch_size=128)\n",
    "print(loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLz1jkd7iziI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swPQMAxzizkZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQ9KFcuKizm7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XrLmbOlizpj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4KQQEMaizsJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqMVmcQeizgX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_20UiqMd6D8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5_39X-Yd6GY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpvumrPq2VYm"
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "\n",
    "from attention_utils import get_activations, get_data_recurrent\n",
    "\n",
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 20\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n",
    "\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n",
    "\n",
    "\n",
    "def model_attention_applied_after_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    lstm_units = 32\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_attention_applied_before_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    attention_mul = attention_3d_block(inputs)\n",
    "    lstm_units = 32\n",
    "    attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    N = 300000\n",
    "    # N = 300 -> too few = no training\n",
    "    inputs_1, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM)\n",
    "\n",
    "    if APPLY_ATTENTION_BEFORE_LSTM:\n",
    "        m = model_attention_applied_before_lstm()\n",
    "    else:\n",
    "        m = model_attention_applied_after_lstm()\n",
    "\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(m.summary())\n",
    "\n",
    "    m.fit([inputs_1], outputs, epochs=1, batch_size=64, validation_split=0.1)\n",
    "\n",
    "    attention_vectors = []\n",
    "    for i in range(300):\n",
    "        testing_inputs_1, testing_outputs = get_data_recurrent(1, TIME_STEPS, INPUT_DIM)\n",
    "        attention_vector = np.mean(get_activations(m,\n",
    "                                                   testing_inputs_1,\n",
    "                                                   print_shape_only=True,\n",
    "                                                   layer_name='attention_vec')[0], axis=2).squeeze()\n",
    "        print('attention =', attention_vector)\n",
    "        assert (np.sum(attention_vector) - 1.0) < 1e-5\n",
    "        attention_vectors.append(attention_vector)\n",
    "\n",
    "    attention_vector_final = np.mean(np.array(attention_vectors), axis=0)\n",
    "    # plot part.\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                         title='Attention Mechanism as '\n",
    "                                                                               'a function of input'\n",
    "                                                                               ' dimensions.')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBzQ7ZEd3sf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyA5a0Wu2mG4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eO7c8W8fd4uE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "087VjDaQd4wl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7I1bY48kd4zO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ebaZVWqd41q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r00pFztgd44l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "nlp_nlu",
   "language": "python",
   "name": "nlp_nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
